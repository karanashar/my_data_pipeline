{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report,roc_auc_score,roc_curve\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory structure to store our assets i.e fitted models and transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('assets/scaler')\n",
    "os.makedirs('assets/models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do customized operations according to project requirement\n",
    "def pre_process(file,training):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preparation Steps\n",
    "file=pd.read_csv('file_name.csv')\n",
    "train_final_df=pre_process(file,training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y=train_final_df['y']\n",
    "train_final_df.drop(columns=['y'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a dictionary to store information about the scalers.\n",
    "<p> 1. The object on which the scaler is to be fitted on. \n",
    "<p> 2. The location where the fitted object is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers={'MinMax':{'scaler':MinMaxScaler(),'fitted_scaler':None}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to fit or transform a DataFrame using a Scaler.\n",
    "<p> If training==True then the 'fit' operation would be carried out and after fitting the scaler would be stored in the assets directory.\n",
    "<p> If training==False then the 'transform' operation would be carried out. The fitted scaler would be loaded from the location and transformation would take place.\n",
    "<p>Note: The details of the Scaler should be available in the dictionary - 'scalers'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(data,training,scaler_type):\n",
    "    if training==True:\n",
    "        scaler=scalers.get(scaler_type).get('scaler')\n",
    "        scaler.fit(data)\n",
    "        to_save='assets/scaler/{}.gz'.format(scaler_type)\n",
    "        joblib.dump(scaler,to_save)\n",
    "        scalers.get(scaler_type)['fitted_scaler']=to_save\n",
    "    if training==False:\n",
    "        path=scalers.get(scaler_type).get('fitted_scaler')\n",
    "        scaler=joblib.load(path)\n",
    "        scaled_data=scaler.transform(data)\n",
    "        return scaled_data         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a MinMax scaler on our entire training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling(train_final_df,True,'MinMax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled_df=pd.DataFrame(scaling(train_final_df,False,'MinMax'),columns=train_final_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train=train_scaled_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = ExtraTreesClassifier(n_estimators=100,random_state=1)\n",
    "fit = best_features.fit(features_train,train_Y)\n",
    "scores = pd.DataFrame(fit.feature_importances_)\n",
    "columns = pd.DataFrame(features_train.columns)\n",
    "feature_importances = pd.concat([columns,scores],axis=1)\n",
    "feature_importances.columns = ['Features','Score']  \n",
    "\n",
    "\n",
    "importance = pd.Series(fit.feature_importances_, index=features_train.columns)\n",
    "importance.sort_values().plot(kind='barh',figsize=(10,5))\n",
    "plt.title('Feature Importances in Descending order')\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(train_scaled_df,train_Y,test_size=0.30,stratify=train_Y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the explanations of the functions used:\n",
    "<p>1.model_train_K_fold - Train a model using Stratified K-Fold cross validation. Stores the trained model in the assets directory. You also need to pass the models and parameters dictionary object\n",
    "<p>2.model_predict - Use the trained models to predict new data. If Probability==True return the probability instead of the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train_K_fold(features,target,algo,models,parameters,K=8):\n",
    "    kfold = StratifiedKFold(n_splits=K,shuffle=True,random_state=1)   \n",
    "    clf = GridSearchCV(estimator=models.get(algo).get('model'), param_grid=parameters.get(algo), cv=kfold, verbose=0, scoring='accuracy',refit=True)\n",
    "    best_model = clf.fit(X_train,y_train)\n",
    "    to_save='assets/models/{}.gz'.format(algo)\n",
    "    joblib.dump(best_model,to_save)\n",
    "    models.get(algo)['fitted_model']=to_save\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(features,algo,probability=False):\n",
    "    model=joblib.load('assets/models/{}.gz'.format(algo))\n",
    "    if probability==False:\n",
    "        prediction=model.predict(features)\n",
    "    if probability==True:\n",
    "        prediction=model.predict_proba(features)\n",
    "        prediction=prediction[:,1]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 1. models - A dictionary containing different models and the location where the fitted model is stored\n",
    "<p> 2. parameters - A dictionary containing the parameters for every model which the grid_search would search on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models={'random_forest':{'model':RandomForestClassifier(random_state=1),'fitted_model':None},\n",
    "       'logistic_regression':{'model':LogisticRegression(random_state=1),'fitted_model':None},\n",
    "       'gradient_boosting_classifier':{'model':GradientBoostingClassifier(random_state=1),'fitted_model':None},\n",
    "       'svm':{'model':SVC(random_state=1),'fitted_model':None}\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={'random_forest':{'n_estimators':[100,500],\n",
    "                            'max_depth':[4,8]},\n",
    "           'logistic_regression':{'C':[0.01,1,10],\n",
    "                                  'penalty': ['l2'],\n",
    "                                  'max_iter':[1000]},\n",
    "            'gradient_boosting_classifier':{'learning_rate': [0.1,0.2],\n",
    "                                            'min_samples_split': [2,4],\n",
    "                                            'n_estimators':[100,200]},\n",
    "            'svm': {'kernel':['poly','rbf'],\n",
    "                    'C':[0.5,1,10],\n",
    "                   'probability':[True]}\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_K_fold(X_train,y_train,'random_forest',models,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_K_fold(X_train,y_train,'logistic_regression',models,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_K_fold(X_train,y_train,'gradient_boosting_classifier',models,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_K_fold(X_train,y_train,'svm',models,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=joblib.load(models.get('logistic_regression').get('fitted_model'))\n",
    "pd.DataFrame(lr.best_estimator_.coef_,columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretations \n",
    "<p> 1. For an increase in number_of_stops the log-odds for the trip to be classified as 'interesting' increases\n",
    "<p> 2. For an increase in feature9 the log-odds for the trip to be classified as 'interesting' decreases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Hyper-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to retrive the best hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_hyper_parameters(algo,models):\n",
    "    model=joblib.load(models.get(algo).get('fitted_model'))\n",
    "    return model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in models.keys():\n",
    "    print('{}: {}'.format(i,get_best_hyper_parameters(i,models)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting Score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to report:\n",
    "<p> 1.K-fold Validation Score\n",
    "<p> 2.Area Under ROC Curve for Test Data\n",
    "<p> 3.Confusion Matrix of the Test Data \n",
    "<p> 4.Classification Report of the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_scores(algo,X_test,y_test,models):\n",
    "    print(algo)\n",
    "    model=joblib.load(models.get(algo).get('fitted_model'))\n",
    "    prediction=model.predict(X_test)\n",
    "    print('K-fold Validation Score: {}'.format(model.best_score_))\n",
    "    print('\\nTest Set Results: \\n')\n",
    "    print('Area Under ROC curve test set  {}'.format(roc_auc_score(y_test,prediction)))\n",
    "    print(confusion_matrix(y_test,prediction))\n",
    "    print(classification_report(y_test,prediction))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in models.keys():\n",
    "    report_scores(i,X_test,y_test,models)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ensemble=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in models.keys():\n",
    "    test_prediction=model_predict(X_test,i,probability=True)\n",
    "    test_ensemble['{}_prediction'.format(i)]=test_prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ensemble['average']=test_ensemble.sum(axis=1)/(len(test_ensemble.columns)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Optimum Thresold - Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, test_ensemble['average'])\n",
    "# get the best threshold\n",
    "J = tpr - fpr\n",
    "ix = argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold=%f' % (best_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ensemble['ensemble_prediction']=np.where(test_ensemble['average'] >= best_thresh, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,test_ensemble['ensemble_prediction']))\n",
    "print(classification_report(y_test,test_ensemble['ensemble_prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,test_ensemble['ensemble_prediction']))\n",
    "print(classification_report(y_test,test_ensemble['ensemble_prediction']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the models dictionary, scaler dictionary and best_threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(models,'assets/models/models_dict.gz')\n",
    "joblib.dump(scalers,'assets/scaler/scaler_dict.gz')\n",
    "joblib.dump(best_threshold,'assets/best_threshold.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The test run is designed in such a way that it can run individually. There are no dependencies with the code above. Only the required functions need to be imported.\n",
    "<p> You only need to enter the '.csv' file name and the '.zip' folder name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Loading Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=joblib.load('assets/models/models_dict.gz')\n",
    "scalers=joblib.load('assets/scaler/scaler_dict.gz')\n",
    "best_threshold=joblib.load('assets/best_threshold.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Pre-Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing\n",
    "file=pd.read_csv('file_name.csv')\n",
    "prediction_final_df=pre_process(file,training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_file_name=prediction_final_df[['filename']]\n",
    "prediction_final_df.drop(columns=['filename'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Scaling Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_scaled_df=pd.DataFrame(scaling(prediction_final_df,False,'MinMax'),columns=prediction_final_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Getting prediction for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in models.keys():\n",
    "    prediction_pred=model_predict(prediction_scaled_df,i,probability=True)\n",
    "    prediction_file_name['{}_prediction'.format(i)]=prediction_pred    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Averaging out predictions and predicting according to the best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_file_name['average']=prediction_file_name.iloc[:,1:].sum(axis=1)/(len(prediction_file_name.columns)-1)\n",
    "prediction_file_name['ensemble_prediction']=np.where(prediction_file_name['average'] >= best_thresh, 1, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_file_name['ensemble_prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_file_name[['filename','ensemble_prediction']].to_csv('predictions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customization Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Function to add a model to the model dictionary.\n",
    "<p>Function to add parameters for the model\n",
    "<p>Note - Remember to train the new model using model_train_K_fold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_models(model_name,model_object,models):\n",
    "    models[model_name]={'model':model_object,'fitted_model':None}\n",
    "    return True\n",
    "    \n",
    "def add_parameters(model_name,model_parameters,parameters):\n",
    "    parameters[model_name]=model_parameters\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to add a different scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_scaler(scaler_name,scaler_object,scalers):\n",
    "    scalers[scaler_name]:{'scaler':scaler_object,'fitted_scaler':None}\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The pipeline is made modular.\n",
    "<p>A new model can be added easily.\n",
    "<p>New parameters can be added and tested easily.\n",
    "<p>To predict on a new file all we need to do is just change the location of where the files are present.\n",
    "<p> The two dictionary objects are important components of the pipeline and are easy to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <b> Improvement Suggestions </b>\n",
    "<p>1.Create a data directory \n",
    "<p>2.Current design choice can accomodate only 1 MinMax scaler. Improve that\n",
    "<p>3.Search a larger grid search space   \n",
    "<p>4.Nested K-Fold Cross validation can be carried out to report bias free scores\n",
    "<p>5.Re-train all the models on all the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
